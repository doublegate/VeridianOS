//! Fast path IPC implementation for register-based messages
//!
//! Achieves < 5Î¼s latency by minimizing memory access and using direct register
//! transfers.
//!
//! ## Register mapping
//!
//! The IPC register convention maps to architecture registers as follows:
//! - x86_64:  RDI, RSI, RDX, RCX, R8, R9, R10
//! - AArch64: X0, X1, X2, X3, X4, X5, X6
//! - RISC-V:  a0, a1, a2, a3, a4, a5, a6
//!
//! All share the same semantic layout (see `IPC_REG_*` constants below).

#![allow(dead_code)]

use core::sync::atomic::{AtomicU64, Ordering};

use super::{
    error::{IpcError, Result},
    SmallMessage,
};
use crate::{arch::entropy::read_timestamp, process::pcb::ProcessState, sched::current_process};

/// Performance counter for fast path operations
static FAST_PATH_COUNT: AtomicU64 = AtomicU64::new(0);
static FAST_PATH_CYCLES: AtomicU64 = AtomicU64::new(0);

// IPC register semantic indices (architecture-neutral)
const IPC_REG_CAP: usize = 0; // Capability token
const IPC_REG_OPCODE: usize = 1; // Operation code
const IPC_REG_FLAGS: usize = 2; // Flags
const IPC_REG_DATA0: usize = 3; // Data word 0
const IPC_REG_DATA1: usize = 4; // Data word 1
const IPC_REG_DATA2: usize = 5; // Data word 2
const IPC_REG_DATA3: usize = 6; // Data word 3

/// Architecture-neutral IPC register set.
///
/// Holds the 7 registers used for fast-path IPC message transfer.
/// The layout is the same on all architectures; only the physical register
/// names differ (see module-level documentation).
#[repr(C)]
#[derive(Clone, Copy, Default)]
struct IpcRegs {
    regs: [u64; 7],
}

/// Fast path IPC send for small messages
///
/// This function is designed to be inlined and optimized for minimum latency.
/// It performs direct register transfer without touching memory when possible.
#[inline(always)]
pub fn fast_send(msg: &SmallMessage, target_pid: u64) -> Result<()> {
    let start = read_timestamp();

    // Quick capability validation (should be cached)
    if !validate_capability_fast(msg.capability) {
        return Err(IpcError::InvalidCapability);
    }

    // Find target process (O(1) lookup)
    let target = match find_process_fast(target_pid) {
        Some(p) => p,
        None => return Err(IpcError::ProcessNotFound),
    };

    // Check if target is waiting for message
    if target.state == ProcessState::Blocked {
        // Direct transfer path - this is the fast case
        transfer_registers(msg, &mut target.context);

        // Wake up receiver and switch to it
        target.state = ProcessState::Ready;
        // TODO(future): Implement direct process switch via scheduler

        // Update performance counters
        let elapsed = read_timestamp() - start;
        FAST_PATH_COUNT.fetch_add(1, Ordering::Relaxed);
        FAST_PATH_CYCLES.fetch_add(elapsed, Ordering::Relaxed);

        Ok(())
    } else {
        // Target not ready, fall back to queuing
        Err(IpcError::WouldBlock)
    }
}

/// Fast path IPC receive
#[inline(always)]
pub fn fast_receive(endpoint: u64, timeout: Option<u64>) -> Result<SmallMessage> {
    let current = current_process();

    // Check if message already waiting
    if let Some(msg) = check_pending_message(endpoint) {
        return Ok(msg);
    }

    // Block current process
    current.state = ProcessState::Blocked;
    current.blocked_on = Some(endpoint);

    // Yield CPU and wait for message
    yield_and_wait(timeout)?;

    // When we wake up, message should be in our IPC register context.
    // TODO(future): Read from the current task's saved IPC register set
    // once per-task IpcRegs storage is implemented.
    let regs = IpcRegs::default();
    Ok(read_message_from_regs(&regs))
}

/// Fast capability validation using cached lookups
#[inline(always)]
fn validate_capability_fast(cap: u64) -> bool {
    // TODO(future): Implement O(1) capability lookup from per-CPU cache
    cap != 0 && cap < 0x10000
}

/// Fast process lookup
///
/// Checks if the target process exists and is blocked (ready for direct
/// register transfer). If blocked, wakes it via the scheduler. Returns
/// None to fall back to the slow path since direct register transfer
/// requires per-task IpcRegs storage (planned for Sprint G-4).
#[inline(always)]
fn find_process_fast(pid: u64) -> Option<&'static mut Process> {
    // Check if target process exists via scheduler
    if let Some(_task) = crate::sched::find_process(crate::process::ProcessId(pid)) {
        // Process exists. Wake it if blocked so it can receive via slow path.
        crate::sched::ipc_blocking::wake_up_process(crate::process::ProcessId(pid));
    }
    // Return None to fall back to slow path (direct register transfer
    // needs per-task IpcRegs, which will be added in Sprint G-4)
    None
}

/// Transfer message into target's IPC registers (architecture-neutral)
#[inline(always)]
fn transfer_registers(msg: &SmallMessage, regs: &mut IpcRegs) {
    regs.regs[IPC_REG_CAP] = msg.capability;
    regs.regs[IPC_REG_OPCODE] = msg.opcode as u64;
    regs.regs[IPC_REG_FLAGS] = msg.flags as u64;
    regs.regs[IPC_REG_DATA0] = msg.data[0];
    regs.regs[IPC_REG_DATA1] = msg.data[1];
    regs.regs[IPC_REG_DATA2] = msg.data[2];
    regs.regs[IPC_REG_DATA3] = msg.data[3];
}

/// Read message from IPC registers (architecture-neutral)
#[inline(always)]
fn read_message_from_regs(regs: &IpcRegs) -> SmallMessage {
    SmallMessage {
        capability: regs.regs[IPC_REG_CAP],
        opcode: regs.regs[IPC_REG_OPCODE] as u32,
        flags: regs.regs[IPC_REG_FLAGS] as u32,
        data: [
            regs.regs[IPC_REG_DATA0],
            regs.regs[IPC_REG_DATA1],
            regs.regs[IPC_REG_DATA2],
            regs.regs[IPC_REG_DATA3],
        ],
    }
}

/// Check for pending messages without blocking
fn check_pending_message(_endpoint: u64) -> Option<SmallMessage> {
    // TODO(future): Check message queue for pending messages
    None
}

/// Yield CPU and wait for message or timeout
fn yield_and_wait(_timeout: Option<u64>) -> Result<()> {
    // TODO(future): Implement scheduler yield with optional timeout
    Ok(())
}

// Placeholder process type for fast-path IPC
#[allow(dead_code)]
struct Process {
    pid: u64,
    state: ProcessState,
    blocked_on: Option<u64>,
    context: IpcRegs,
}

/// Get performance statistics
pub fn get_fast_path_stats() -> (u64, u64) {
    let count = FAST_PATH_COUNT.load(Ordering::Relaxed);
    let cycles = FAST_PATH_CYCLES.load(Ordering::Relaxed);
    let avg_cycles = if count > 0 { cycles / count } else { 0 };
    (count, avg_cycles)
}

#[cfg(all(test, not(target_os = "none")))]
mod tests {
    use super::*;

    #[test]
    fn test_fast_path_stats() {
        let (count, avg) = get_fast_path_stats();
        assert_eq!(count, 0);
        assert_eq!(avg, 0);
    }
}
